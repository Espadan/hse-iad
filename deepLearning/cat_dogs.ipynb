{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "7m-3KHuCy-8F"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "!unzip \"/content/gdrive/My Drive/Colab Notebooks/small.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "MVePSjQ9QWiR"
   },
   "outputs": [],
   "source": [
    "train_dir='small/train/'\n",
    "validation_dir='small/validation/'\n",
    "test_dir='small/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dB_sXbyxUTpD"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.preprocessing import image\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Reshape,AveragePooling2D, SeparableConv2D,Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "VDRsXIpbObYP"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Reshape,AveragePooling2D, SeparableConv2D,Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 512 images belonging to 2 classes.\n",
      "Found 256 images belonging to 2 classes.\n",
      "Found 256 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import mobilenet,mobilenetv2\n",
    "net_model=mobilenet\n",
    "net_description='mobilenet'\n",
    "\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=net_model.preprocess_input)\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=net_model.preprocess_input)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        # This is the target directory\n",
    "        train_dir,\n",
    "        target_size=(INPUT_SHAPE, INPUT_SHAPE),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='binary')\n",
    "train_generator.shuffle = False\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(INPUT_SHAPE, INPUT_SHAPE),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='binary')\n",
    "validation_generator.shuffle = False\n",
    "\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(INPUT_SHAPE, INPUT_SHAPE),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='binary')\n",
    "test_generator.shuffle = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6766,
     "status": "ok",
     "timestamp": 1554710670191,
     "user": {
      "displayName": "Andrey Savchenko",
      "photoUrl": "",
      "userId": "10284387503507973825"
     },
     "user_tz": -180
    },
    "id": "5VGr5teOc1ts",
    "outputId": "d6cabb40-7a2d-411d-9368-b9af5a7b2f36"
   },
   "outputs": [],
   "source": [
    "model = mobilenet.MobileNet(weights='imagenet',input_shape=(INPUT_SHAPE,INPUT_SHAPE, 3),include_top=False, pooling='avg')\n",
    "train_features = model.predict_generator(train_generator)\n",
    "validation_features = model.predict_generator(validation_generator)\n",
    "test_features = model.predict_generator(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 1024) (256, 1024) (256, 1024)\n"
     ]
    }
   ],
   "source": [
    "print(train_features.shape, validation_features.shape, test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_generator.labels[train_generator.index_array]\n",
    "y_validation = validation_generator.labels[validation_generator.index_array]\n",
    "y_test = test_generator.labels[test_generator.index_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512 256 256\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train), len(y_validation), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.98      0.98       128\n",
      "          1       0.98      0.97      0.98       128\n",
      "\n",
      "avg / total       0.98      0.98      0.98       256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "classifier_1 = KNeighborsClassifier(n_neighbors=1)\n",
    "classifier_1.fit(train_features, y_train) \n",
    "\n",
    "preds = classifier_1.predict(validation_features)\n",
    "\n",
    "print(classification_report(y_validation, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.99      0.98       128\n",
      "          1       0.99      0.97      0.98       128\n",
      "\n",
      "avg / total       0.98      0.98      0.98       256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier_1 = KNeighborsClassifier(n_neighbors=30)\n",
    "classifier_1.fit(train_features, y_train) \n",
    "\n",
    "preds = classifier_1.predict(validation_features)\n",
    "\n",
    "print(classification_report(y_validation, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.99      0.98       128\n",
      "          1       0.99      0.98      0.98       128\n",
      "\n",
      "avg / total       0.98      0.98      0.98       256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier_1 = KNeighborsClassifier(n_neighbors=50)\n",
    "classifier_1.fit(train_features, y_train) \n",
    "\n",
    "preds = classifier_1.predict(validation_features)\n",
    "\n",
    "print(classification_report(y_validation, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.99      0.98       128\n",
      "          1       0.99      0.96      0.98       128\n",
      "\n",
      "avg / total       0.98      0.98      0.98       256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier_1 = KNeighborsClassifier(n_neighbors=80)\n",
    "classifier_1.fit(train_features, y_train) \n",
    "\n",
    "preds = classifier_1.predict(validation_features)\n",
    "\n",
    "print(classification_report(y_validation, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test best model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.98      0.98       128\n",
      "          1       0.98      0.98      0.98       128\n",
      "\n",
      "avg / total       0.98      0.98      0.98       256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier_1 = KNeighborsClassifier(n_neighbors=1)\n",
    "classifier_1.fit(train_features, y_train) \n",
    "\n",
    "preds = classifier_1.predict(test_features)\n",
    "\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       cats       0.98      0.99      0.98       128\n",
      "       dogs       0.99      0.98      0.98       128\n",
      "\n",
      "avg / total       0.98      0.98      0.98       256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "classifier_2 = SVC(kernel='linear')\n",
    "classifier_2.fit(train_features, y_train) \n",
    "\n",
    "preds = classifier_2.predict(validation_features)\n",
    "print(classification_report(y_validation, preds, target_names=['cats', 'dogs']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       cats       0.98      0.98      0.98       128\n",
      "       dogs       0.98      0.98      0.98       128\n",
      "\n",
      "avg / total       0.98      0.98      0.98       256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "classifier_2 = SVC(kernel='poly')\n",
    "classifier_2.fit(train_features, y_train) \n",
    "\n",
    "preds = classifier_2.predict(validation_features)\n",
    "print(classification_report(y_validation, preds, target_names=['cats', 'dogs']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test best model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       cats       0.98      0.99      0.99       128\n",
      "       dogs       0.99      0.98      0.99       128\n",
      "\n",
      "avg / total       0.99      0.99      0.99       256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "classifier_2 = SVC(kernel='linear')\n",
    "classifier_2.fit(train_features, y_train) \n",
    "\n",
    "preds = classifier_2.predict(test_features)\n",
    "print(classification_report(y_test, preds, target_names=['cats', 'dogs']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       cats       0.98      0.98      0.98       128\n",
      "       dogs       0.98      0.98      0.98       128\n",
      "\n",
      "avg / total       0.98      0.98      0.98       256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "classifier_3 = ensemble.RandomForestClassifier(n_estimators = 25)\n",
    "classifier_3.fit(train_features, y_train) \n",
    "\n",
    "preds = classifier_3.predict(validation_features)\n",
    "print(classification_report(y_validation, preds, target_names=['cats', 'dogs']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       cats       0.95      0.97      0.96       128\n",
      "       dogs       0.97      0.95      0.96       128\n",
      "\n",
      "avg / total       0.96      0.96      0.96       256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier_3 = ensemble.RandomForestClassifier(n_estimators = 10)\n",
    "classifier_3.fit(train_features, y_train) \n",
    "\n",
    "preds = classifier_3.predict(validation_features)\n",
    "print(classification_report(y_validation, preds, target_names=['cats', 'dogs']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       cats       1.00      0.97      0.98       128\n",
      "       dogs       0.97      1.00      0.98       128\n",
      "\n",
      "avg / total       0.98      0.98      0.98       256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier_3 = ensemble.RandomForestClassifier(n_estimators = 35)\n",
    "classifier_3.fit(train_features, y_train) \n",
    "\n",
    "preds = classifier_3.predict(validation_features)\n",
    "print(classification_report(y_validation, preds, target_names=['cats', 'dogs']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       cats       0.98      0.98      0.98       128\n",
      "       dogs       0.98      0.98      0.98       128\n",
      "\n",
      "avg / total       0.98      0.98      0.98       256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier_3 = ensemble.RandomForestClassifier(n_estimators = 55)\n",
    "classifier_3.fit(train_features, y_train) \n",
    "\n",
    "preds = classifier_3.predict(validation_features)\n",
    "print(classification_report(y_validation, preds, target_names=['cats', 'dogs']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test best model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       cats       0.98      0.97      0.97       128\n",
      "       dogs       0.97      0.98      0.97       128\n",
      "\n",
      "avg / total       0.97      0.97      0.97       256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier_3 = ensemble.RandomForestClassifier(n_estimators = 25)\n",
    "classifier_3.fit(train_features, y_train) \n",
    "\n",
    "preds = classifier_3.predict(test_features)\n",
    "print(classification_report(y_test, preds, target_names=['cats', 'dogs']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       cats       0.99      0.97      0.98       128\n",
      "       dogs       0.97      0.99      0.98       128\n",
      "\n",
      "avg / total       0.98      0.98      0.98       256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier_4 = ensemble.ExtraTreesClassifier(n_estimators = 25)\n",
    "classifier_4.fit(train_features, y_train) \n",
    "\n",
    "preds = classifier_4.predict(validation_features)\n",
    "print(classification_report(y_validation, preds, target_names=['cats', 'dogs']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       cats       0.95      0.98      0.96       128\n",
      "       dogs       0.98      0.95      0.96       128\n",
      "\n",
      "avg / total       0.96      0.96      0.96       256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier_4 = ensemble.ExtraTreesClassifier(n_estimators = 10)\n",
    "classifier_4.fit(train_features, y_train) \n",
    "\n",
    "preds = classifier_4.predict(validation_features)\n",
    "print(classification_report(y_validation, preds, target_names=['cats', 'dogs']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       cats       0.96      0.98      0.97       128\n",
      "       dogs       0.98      0.96      0.97       128\n",
      "\n",
      "avg / total       0.97      0.97      0.97       256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier_4 = ensemble.ExtraTreesClassifier(n_estimators = 35)\n",
    "classifier_4.fit(train_features, y_train) \n",
    "\n",
    "preds = classifier_4.predict(validation_features)\n",
    "print(classification_report(y_validation, preds, target_names=['cats', 'dogs']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       cats       0.99      0.98      0.98       128\n",
      "       dogs       0.98      0.99      0.98       128\n",
      "\n",
      "avg / total       0.98      0.98      0.98       256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier_4 = ensemble.RandomForestClassifier(n_estimators = 55)\n",
    "classifier_4.fit(train_features, y_train) \n",
    "\n",
    "preds = classifier_4.predict(validation_features)\n",
    "print(classification_report(y_validation, preds, target_names=['cats', 'dogs']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test best model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       cats       1.00      0.98      0.99       128\n",
      "       dogs       0.98      1.00      0.99       128\n",
      "\n",
      "avg / total       0.99      0.99      0.99       256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier_4 = ensemble.RandomForestClassifier(n_estimators = 35)\n",
    "classifier_4.fit(train_features, y_train) \n",
    "\n",
    "preds = classifier_4.predict(test_features)\n",
    "print(classification_report(y_test, preds, target_names=['cats', 'dogs']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 512 images belonging to 2 classes.\n",
      "Found 256 images belonging to 2 classes.\n",
      "Found 256 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import resnet\n",
    "net_model=resnet\n",
    "\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=net_model.preprocess_input)\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=net_model.preprocess_input)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        # This is the target directory\n",
    "        train_dir,\n",
    "        target_size=(INPUT_SHAPE, INPUT_SHAPE),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='binary')\n",
    "train_generator.shuffle = False\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(INPUT_SHAPE, INPUT_SHAPE),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='binary')\n",
    "validation_generator.shuffle = False\n",
    "\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(INPUT_SHAPE, INPUT_SHAPE),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='binary')\n",
    "test_generator.shuffle = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6766,
     "status": "ok",
     "timestamp": 1554710670191,
     "user": {
      "displayName": "Andrey Savchenko",
      "photoUrl": "",
      "userId": "10284387503507973825"
     },
     "user_tz": -180
    },
    "id": "5VGr5teOc1ts",
    "outputId": "d6cabb40-7a2d-411d-9368-b9af5a7b2f36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet101_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "171450368/171446536 [==============================] - 146s 1us/step\n"
     ]
    }
   ],
   "source": [
    "model = resnet.ResNet101(weights='imagenet',input_shape=(INPUT_SHAPE,INPUT_SHAPE, 3),include_top=False, pooling='avg')\n",
    "train_features = model.predict_generator(train_generator)\n",
    "validation_features = model.predict_generator(validation_generator)\n",
    "test_features = model.predict_generator(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 2048) (256, 2048) (256, 2048)\n"
     ]
    }
   ],
   "source": [
    "print(train_features.shape, validation_features.shape, test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = train_generator.labels[train_generator.index_array]\n",
    "y_validation = validation_generator.labels[validation_generator.index_array]\n",
    "y_test = test_generator.labels[test_generator.index_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512 256 256\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train), len(y_validation), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.98      0.98       128\n",
      "          1       0.98      0.98      0.98       128\n",
      "\n",
      "avg / total       0.98      0.98      0.98       256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "classifier_1 = KNeighborsClassifier(n_neighbors=1)\n",
    "classifier_1.fit(train_features, y_train) \n",
    "\n",
    "preds = classifier_1.predict(validation_features)\n",
    "\n",
    "print(classification_report(y_validation, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98       128\n",
      "          1       1.00      0.97      0.98       128\n",
      "\n",
      "avg / total       0.98      0.98      0.98       256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier_1 = KNeighborsClassifier(n_neighbors=30)\n",
    "classifier_1.fit(train_features, y_train) \n",
    "\n",
    "preds = classifier_1.predict(validation_features)\n",
    "\n",
    "print(classification_report(y_validation, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99       128\n",
      "          1       1.00      0.98      0.99       128\n",
      "\n",
      "avg / total       0.99      0.99      0.99       256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier_1 = KNeighborsClassifier(n_neighbors=50)\n",
    "classifier_1.fit(train_features, y_train) \n",
    "\n",
    "preds = classifier_1.predict(validation_features)\n",
    "\n",
    "print(classification_report(y_validation, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99       128\n",
      "          1       1.00      0.98      0.99       128\n",
      "\n",
      "avg / total       0.99      0.99      0.99       256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier_1 = KNeighborsClassifier(n_neighbors=80)\n",
    "classifier_1.fit(train_features, y_train) \n",
    "\n",
    "preds = classifier_1.predict(validation_features)\n",
    "\n",
    "print(classification_report(y_validation, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test best model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99       128\n",
      "          1       1.00      0.98      0.99       128\n",
      "\n",
      "avg / total       0.99      0.99      0.99       256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier_1 = KNeighborsClassifier(n_neighbors=90)\n",
    "classifier_1.fit(train_features, y_train) \n",
    "\n",
    "preds = classifier_1.predict(test_features)\n",
    "\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       cats       0.98      1.00      0.99       128\n",
      "       dogs       1.00      0.98      0.99       128\n",
      "\n",
      "avg / total       0.99      0.99      0.99       256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "classifier_2 = SVC(kernel='linear')\n",
    "classifier_2.fit(train_features, y_train) \n",
    "\n",
    "preds = classifier_2.predict(validation_features)\n",
    "print(classification_report(y_validation, preds, target_names=['cats', 'dogs']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       cats       0.97      0.98      0.98       128\n",
      "       dogs       0.98      0.97      0.98       128\n",
      "\n",
      "avg / total       0.98      0.98      0.98       256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "classifier_2 = SVC(kernel='poly')\n",
    "classifier_2.fit(train_features, y_train) \n",
    "\n",
    "preds = classifier_2.predict(validation_features)\n",
    "print(classification_report(y_validation, preds, target_names=['cats', 'dogs']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test best model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       cats       0.99      1.00      1.00       128\n",
      "       dogs       1.00      0.99      1.00       128\n",
      "\n",
      "avg / total       1.00      1.00      1.00       256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "classifier_2 = SVC(kernel='linear')\n",
    "classifier_2.fit(train_features, y_train) \n",
    "\n",
    "preds = classifier_2.predict(test_features)\n",
    "print(classification_report(y_test, preds, target_names=['cats', 'dogs']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       cats       0.98      0.98      0.98       128\n",
      "       dogs       0.98      0.98      0.98       128\n",
      "\n",
      "avg / total       0.98      0.98      0.98       256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "classifier_3 = ensemble.RandomForestClassifier(n_estimators = 25)\n",
    "classifier_3.fit(train_features, y_train) \n",
    "\n",
    "preds = classifier_3.predict(validation_features)\n",
    "print(classification_report(y_validation, preds, target_names=['cats', 'dogs']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       cats       0.96      0.98      0.97       128\n",
      "       dogs       0.98      0.96      0.97       128\n",
      "\n",
      "avg / total       0.97      0.97      0.97       256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier_3 = ensemble.RandomForestClassifier(n_estimators = 10)\n",
    "classifier_3.fit(train_features, y_train) \n",
    "\n",
    "preds = classifier_3.predict(validation_features)\n",
    "print(classification_report(y_validation, preds, target_names=['cats', 'dogs']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       cats       0.98      0.99      0.98       128\n",
      "       dogs       0.99      0.98      0.98       128\n",
      "\n",
      "avg / total       0.98      0.98      0.98       256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier_3 = ensemble.RandomForestClassifier(n_estimators = 35)\n",
    "classifier_3.fit(train_features, y_train) \n",
    "\n",
    "preds = classifier_3.predict(validation_features)\n",
    "print(classification_report(y_validation, preds, target_names=['cats', 'dogs']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       cats       0.98      0.98      0.98       128\n",
      "       dogs       0.98      0.98      0.98       128\n",
      "\n",
      "avg / total       0.98      0.98      0.98       256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier_3 = ensemble.RandomForestClassifier(n_estimators = 55)\n",
    "classifier_3.fit(train_features, y_train) \n",
    "\n",
    "preds = classifier_3.predict(validation_features)\n",
    "print(classification_report(y_validation, preds, target_names=['cats', 'dogs']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test best model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       cats       0.99      1.00      1.00       128\n",
      "       dogs       1.00      0.99      1.00       128\n",
      "\n",
      "avg / total       1.00      1.00      1.00       256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier_3 = ensemble.RandomForestClassifier(n_estimators = 25)\n",
    "classifier_3.fit(train_features, y_train) \n",
    "\n",
    "preds = classifier_3.predict(test_features)\n",
    "print(classification_report(y_test, preds, target_names=['cats', 'dogs']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       cats       0.98      0.98      0.98       128\n",
      "       dogs       0.98      0.98      0.98       128\n",
      "\n",
      "avg / total       0.98      0.98      0.98       256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier_4 = ensemble.ExtraTreesClassifier(n_estimators = 25)\n",
    "classifier_4.fit(train_features, y_train) \n",
    "\n",
    "preds = classifier_4.predict(validation_features)\n",
    "print(classification_report(y_validation, preds, target_names=['cats', 'dogs']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       cats       0.95      0.97      0.96       128\n",
      "       dogs       0.97      0.95      0.96       128\n",
      "\n",
      "avg / total       0.96      0.96      0.96       256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier_4 = ensemble.ExtraTreesClassifier(n_estimators = 10)\n",
    "classifier_4.fit(train_features, y_train) \n",
    "\n",
    "preds = classifier_4.predict(validation_features)\n",
    "print(classification_report(y_validation, preds, target_names=['cats', 'dogs']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       cats       0.98      0.97      0.98       128\n",
      "       dogs       0.97      0.98      0.98       128\n",
      "\n",
      "avg / total       0.98      0.98      0.98       256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier_4 = ensemble.ExtraTreesClassifier(n_estimators = 35)\n",
    "classifier_4.fit(train_features, y_train) \n",
    "\n",
    "preds = classifier_4.predict(validation_features)\n",
    "print(classification_report(y_validation, preds, target_names=['cats', 'dogs']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       cats       0.98      0.98      0.98       128\n",
      "       dogs       0.98      0.98      0.98       128\n",
      "\n",
      "avg / total       0.98      0.98      0.98       256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier_4 = ensemble.RandomForestClassifier(n_estimators = 55)\n",
    "classifier_4.fit(train_features, y_train) \n",
    "\n",
    "preds = classifier_4.predict(validation_features)\n",
    "print(classification_report(y_validation, preds, target_names=['cats', 'dogs']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test best model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       cats       0.99      0.98      0.99       128\n",
      "       dogs       0.98      0.99      0.99       128\n",
      "\n",
      "avg / total       0.99      0.99      0.99       256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier_4 = ensemble.RandomForestClassifier(n_estimators = 35)\n",
    "classifier_4.fit(train_features, y_train) \n",
    "\n",
    "preds = classifier_4.predict(test_features)\n",
    "print(classification_report(y_test, preds, target_names=['cats', 'dogs']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cat_dogs.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
